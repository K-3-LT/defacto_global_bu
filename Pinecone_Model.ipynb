{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-3-LT/defacto_global_bu/blob/main/Pinecone_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "-bL-NOSDcIii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx openai transformers pinecone-client"
      ],
      "metadata": {
        "id": "mszQaRJdciRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "import openai\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from transformers import GPT2Tokenizer\n",
        "from google.colab import files\n",
        "import pinecone\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "aDTJE3tFcLWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read word doc\n",
        "def read_docx(file_path):\n",
        "  doc = docx.Document(file_path)\n",
        "  #files.upload()\n",
        "  text = []\n",
        "  for paragraph in doc.paragraphs:\n",
        "    # skip links\n",
        "    if 'http://' not in paragraph.text and 'https://' not in paragraph.text:\n",
        "      text.append(paragraph.text)\n",
        "  return '\\n'.join(text)"
      ],
      "metadata": {
        "id": "qw4etnIwdJao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = read_docx('/content/defacto.docx')\n",
        "\n",
        "# split content into small paragraphs\n",
        "paragraphs = content.split('\\n')\n",
        "\n",
        "# Input openai api\n",
        "api_key = input(\"Please ensure proper inputting of OpenAI API key:\")\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Tokenize paragraph\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Make sure each section is less than 4096\n",
        "sections = []\n",
        "current_section = \"\"\n",
        "for paragraph in paragraphs:\n",
        "  tokens = tokenizer.encode(paragraph, add_special_tokens=False)\n",
        "  if len(tokens) + len(tokenizer.encode(current_section, add_special_tokens=False)) > 4000:\n",
        "    current_section += '\\n'\n",
        "    sections.append(current_section)\n",
        "    current_section = paragraph\n",
        "  else:\n",
        "    current_section += f'\\n{paragraph}'\n",
        "\n",
        "if current_section:\n",
        "  sections.append(current_section)\n",
        "\n",
        "# transfer paragraph into embedding\n",
        "def create_embedding(section):\n",
        "  model_engine = \"text-embedding-ada-002\"\n",
        "  openai.api_key = api_key\n",
        "  response = openai.Embedding.create(\n",
        "      model=model_engine,\n",
        "      input=section,\n",
        "  )\n",
        "  return response['data'][0]['embedding']\n",
        "\n",
        "embeddings = [create_embedding(section) for section in tqdm(sections)]\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "usUPt3Kuds-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone API key\n",
        "pinecone_api_key = input(\"Please enter your Pinecone API key: \")\n",
        "pinecone_environment = input(\"Please enter your Pinecone Environment: \")\n",
        "\n",
        "# Pinecone index name\n",
        "index_name = input(\"please enter your Pinecone vector database index name(only lower-case characters or number): \")\n",
        "\n",
        "# Initial Pinecone\n",
        "pinecone.init(api_key=pinecone_api_key,environment=pinecone_environment)\n",
        "\n",
        "# Create a new Pinecone index\n",
        "pinecone.create_index(name = index_name, dimension=len(embeddings[0]),metric='cosine', pod_type='p2')\n",
        "\n",
        "# Access index instance\n",
        "index = pinecone.Index(index_name=index_name)\n",
        "\n",
        "# Create metadata list\n",
        "metadata = [{\"report_context\": section} for section in sections]\n",
        "\n",
        "# upsert vectors and metadata into index\n",
        "for i, (embedding, meta) in enumerate(zip(embeddings, metadata)):\n",
        "  index.upsert(vectors=[(str(i), embedding, meta)])"
      ],
      "metadata": {
        "id": "PEbp6EHYhayf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}