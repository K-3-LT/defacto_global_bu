{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-3-LT/defacto_global_bu/blob/main/Query.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai pinecone-client"
      ],
      "metadata": {
        "id": "uZ4ATZV2qsHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPx9OSHxqbAI",
        "outputId": "ff23612a-b651-498c-be5e-8ce3b043ac07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input openai api\n",
        "api_key = 'Fill your openai api here'\n",
        "#input(\"Please ensure proper inputting of OpenAI API key:\")\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "fvKMNZs1q_FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone index name\n",
        "index_name = 'defacto'\n",
        "#input(\"please enter your Pinecone vector database index name(only lower-case characters or number): \")\n",
        "\n",
        "# Pinecone API key\n",
        "pinecone_api_key = 'Fill your pinecone api'\n",
        "#input(\"Please enter your Pinecone API key: \")\n",
        "pinecone_environment = 'Fill your pinecone environment'\n",
        "#input(\"Please enter your Pinecone Environment: \")\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "pinecone.init(\n",
        "    api_key=pinecone_api_key,\n",
        "    environment=pinecone_environment # find next to api key in console\n",
        ")\n",
        "\n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)"
      ],
      "metadata": {
        "id": "V8qrAU-prWBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"What is your question? \")\n",
        "\n",
        "xq = openai.Embedding.create(input=query, engine=\"text-embedding-ada-002\")['data'][0]['embedding']\n",
        "\n",
        "# Find the top 5 match score data\n",
        "res = index.query([xq], top_k=5, include_metadata=True)\n",
        "\n",
        "# Calculate match score and feed the best match data into gpt\n",
        "#for match in res['matches']:\n",
        "    # Store highest score report context\n",
        "    #print(f\"{match['score']:.2f}: {match['metadata']['report_context']}\")\n",
        "\n",
        "info = res['matches'][0]['metadata']['report_context']\n",
        "\n",
        "def ask_question(query, info):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful customer assistant of deFacto Inc..\"},\n",
        "        {\"role\": \"assistant\", \"content\": info},\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\", #gpt-4-0613 / gpt-3.5-turbo-0613\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "print(ask_question(query, info))\n"
      ],
      "metadata": {
        "id": "CCx7p6-kqzxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cbcac8-161b-4fa2-9f77-fa829b7b71c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your question? What do the arrows represent while building a hierarchy?\n",
            "The arrows represent the direction in which a member will be placed in the hierarchy when building it. Here is what each arrow direction indicates:\n",
            "\n",
            "- When the arrow points to the right: The highlighted member will be dropped into the member being hovered over and become a child to that member.\n",
            "- When the arrow points to the bottom: The highlighted member will be dropped below the member being hovered over and be at the same level as that member.\n",
            "\n",
            "By dragging and dropping members and paying attention to the arrows, you can determine whether a member will be a child or at the same level as another member in the hierarchy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6:14"
      ],
      "metadata": {
        "id": "jWnt6cenXTzg"
      }
    }
  ]
}