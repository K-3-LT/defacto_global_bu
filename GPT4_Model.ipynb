{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-3-LT/defacto_global_bu/blob/main/GPT4_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a187739",
      "metadata": {
        "id": "4a187739"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import GPT4All\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from pdf2image import convert_from_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d607378",
      "metadata": {
        "id": "7d607378",
        "outputId": "e22801dc-ddb7-4cdb-a533-c34ff0a8f4dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loader = PyPDFLoader(\"/Users/vibhasgoel/Downloads/defacto1.pdf\")\n",
        "documents = loader.load_and_split()\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7014b47f",
      "metadata": {
        "id": "7014b47f",
        "outputId": "de205380-9176-4acd-bb81-fb2bea8a668b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.11.1-py3-none-any.whl (257 kB)\n",
            "\u001b[K     |████████████████████████████████| 257 kB 1.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from pypdf) (4.5.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-3.11.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f43a3cd5",
      "metadata": {
        "id": "f43a3cd5",
        "outputId": "ceb877b3-ab22-4a14-b900-7b3274436a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deFacto Planning is a performance management solution tool that allows organizations to utilize real-time budgeting, forecasting, analysis and reporting across all functional units. The platform is Microsoft-centric and Tabular-based. deFacto Planning integrates with PowerBI and other Business Intelligence (BI) tools. Reporter functionality is contained within an Excel environment, using the deFacto add-in as well as native Excel functionality.  deFacto is compatible with Excel 2013 and higher Macro security settings in Excel cannot be set to the most restrictive setting Connect using Windows Authentication or Active Directory Recommended to disable Office 365 automatic updates Connect to deFacto – Excel There are two Authentication options available when connecting to the deFacto Excel add-in, depending on server configurations.   If you are logged into your machine with your Windows or Azure credentials, you can opt for the No Password option to gray out the User Name field, and remove the Password field altogether. After your first log in, the URL and User Name will be stored. This option allows for a one-click connection option.\n"
          ]
        }
      ],
      "source": [
        "print(documents[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f580b161",
      "metadata": {
        "id": "f580b161",
        "outputId": "646f409a-f0ef-4ea0-ea8c-6ee9d6580700"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=64\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237a80e3",
      "metadata": {
        "id": "237a80e3",
        "outputId": "af2d515d-1f40-400f-d6e3-e31f85d52993"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-30 21:06:33.610326: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70bc5c4b",
      "metadata": {
        "id": "70bc5c4b"
      },
      "outputs": [],
      "source": [
        "db = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c25afb62",
      "metadata": {
        "id": "c25afb62",
        "outputId": "38b70891-264f-4597-a912-66bf51ea6aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.3.26-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 4.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.28 in ./opt/anaconda3/lib/python3.9/site-packages (from chromadb) (2.31.0)\n",
            "Collecting uvicorn[standard]>=0.18.3\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.5 MB/s eta 0:00:011\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in ./opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.22.4)\n",
            "Collecting posthog>=2.4.0\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pandas>=1.3 in ./opt/anaconda3/lib/python3.9/site-packages (from chromadb) (2.0.3)\n",
            "Collecting clickhouse-connect>=0.5.7\n",
            "  Downloading clickhouse_connect-0.6.4-cp39-cp39-macosx_10_9_x86_64.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 4.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fastapi>=0.85.1\n",
            "  Downloading fastapi-0.99.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 403 kB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9 in ./opt/anaconda3/lib/python3.9/site-packages (from chromadb) (1.10.10)\n",
            "Collecting overrides>=7.3.1\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Collecting hnswlib>=0.7\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in ./opt/anaconda3/lib/python3.9/site-packages (from chromadb) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in ./opt/anaconda3/lib/python3.9/site-packages (from chromadb) (4.5.0)\n",
            "Collecting tqdm>=4.65.0\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1\n",
            "  Downloading onnxruntime-1.15.1-cp39-cp39-macosx_10_15_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 2.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pulsar-client>=3.1.0\n",
            "  Downloading pulsar_client-3.2.0-cp39-cp39-macosx_10_15_universal2.whl (10.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8 MB 3.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting duckdb>=0.7.1\n",
            "  Downloading duckdb-0.8.1-cp39-cp39-macosx_10_9_x86_64.whl (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 4.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pytz in ./opt/anaconda3/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
            "Collecting lz4\n",
            "  Downloading lz4-4.3.2-cp39-cp39-macosx_10_9_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 4.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting zstandard\n",
            "  Downloading zstandard-0.21.0-cp39-cp39-macosx_10_9_x86_64.whl (473 kB)\n",
            "\u001b[K     |████████████████████████████████| 473 kB 1.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: certifi in ./opt/anaconda3/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in ./opt/anaconda3/lib/python3.9/site-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.16)\n",
            "Collecting starlette<0.28.0,>=0.27.0\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 2.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging in ./opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: flatbuffers in ./opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (23.3.3)\n",
            "Requirement already satisfied: sympy in ./opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: protobuf in ./opt/anaconda3/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.2.0)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in ./opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
            "  Downloading uvloop-0.17.0-cp39-cp39-macosx_10_9_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 3.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting httptools>=0.5.0\n",
            "  Downloading httptools-0.5.0-cp39-cp39-macosx_10_9_x86_64.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 4.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting watchfiles>=0.13\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-macosx_10_7_x86_64.whl (405 kB)\n",
            "\u001b[K     |████████████████████████████████| 405 kB 4.7 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in ./opt/anaconda3/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Collecting websockets>=10.4\n",
            "  Downloading websockets-11.0.3-cp39-cp39-macosx_10_9_x86_64.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 4.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting python-dotenv>=0.13\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in ./opt/anaconda3/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (PEP 517) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp39-cp39-macosx_10_9_x86_64.whl size=185695 sha256=81f8eeaaa10a795837a3c42a6d42e5c4bcdba85f88296ac09656b2a386438010\n",
            "  Stored in directory: /Users/vibhasgoel/Library/Caches/pip/wheels/ba/26/61/fface6c407f56418b3140cd7645917f20ba6b27d4e32b2bd20\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: humanfriendly, h11, zstandard, websockets, watchfiles, uvloop, uvicorn, starlette, python-dotenv, monotonic, lz4, httptools, coloredlogs, backoff, tqdm, pulsar-client, posthog, overrides, onnxruntime, hnswlib, fastapi, duckdb, clickhouse-connect, chromadb\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-profiling 3.4.0 requires pandas!=1.4.0,<1.6,>1.1, but you have pandas 2.0.3 which is incompatible.\n",
            "pandas-profiling 3.4.0 requires requests<2.29,>=2.24.0, but you have requests 2.31.0 which is incompatible.\n",
            "pandas-profiling 3.4.0 requires tqdm<4.65,>=4.48.2, but you have tqdm 4.65.0 which is incompatible.\u001b[0m\n",
            "Successfully installed backoff-2.2.1 chromadb-0.3.26 clickhouse-connect-0.6.4 coloredlogs-15.0.1 duckdb-0.8.1 fastapi-0.99.0 h11-0.14.0 hnswlib-0.7.0 httptools-0.5.0 humanfriendly-10.0 lz4-4.3.2 monotonic-1.6 onnxruntime-1.15.1 overrides-7.3.1 posthog-3.0.1 pulsar-client-3.2.0 python-dotenv-1.0.0 starlette-0.27.0 tqdm-4.65.0 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 zstandard-0.21.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b512854",
      "metadata": {
        "id": "9b512854",
        "outputId": "22f17baa-86c3-491c-9296-79b05064da0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found model file at  /Users/vibhasgoel/Downloads/ggml-gpt4all-j-v1.3-groovy.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "objc[65916]: Class GGMLMetalClass is implemented in both /Users/vibhasgoel/opt/anaconda3/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x12d1831c8) and /Users/vibhasgoel/opt/anaconda3/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x12d2bb1c8). One of the two will be used. Which one is undefined.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gptj_model_load: loading model from '/Users/vibhasgoel/Downloads/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
            "gptj_model_load: n_vocab = 50400\n",
            "gptj_model_load: n_ctx   = 2048\n",
            "gptj_model_load: n_embd  = 4096\n",
            "gptj_model_load: n_head  = 16\n",
            "gptj_model_load: n_layer = 28\n",
            "gptj_model_load: n_rot   = 64\n",
            "gptj_model_load: f16     = 2\n",
            "gptj_model_load: ggml ctx size = 5401.45 MB\n",
            "gptj_model_load: kv self size  =  896.00 MB\n",
            "gptj_model_load: ................................... done\n",
            "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
          ]
        }
      ],
      "source": [
        "llm = GPT4All(\n",
        "    model=\"/Users/vibhasgoel/Downloads/ggml-gpt4all-j-v1.3-groovy.bin\",\n",
        "    n_ctx=1000,\n",
        "    backend=\"gptj\",\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e9f59c",
      "metadata": {
        "id": "c9e9f59c"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True,\n",
        "    verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25524f0e",
      "metadata": {
        "id": "25524f0e",
        "outputId": "ce788311-8f88-4a17-c58f-27f0e2b1bc16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " deFacto Planning is an Excel addin that provides performance management, forecasting and reporting across all functional units in Microsoft environment with real-time budgeting capabilities. It integrates into PowerBI along with other BI tools like SQL Server Reporting Services (SSRS) or Crystal Reports to name a few. The platform offers two authentication options such as using Windows Authentication credentials for easy one click connection; otherwise, the No Password option is available where you can gray out User Name field and remove password altogether while logging in once followed by storing URL after which subsequent connections are made with your stored user details like username being used\n",
            " deFacto Planning is an Excel addin that provides performance management, forecasting and reporting across all functional units in Microsoft environment with real-time budgeting capabilities. It integrates into PowerBI along with other BI tools like SQL Server Reporting Services (SSRS) or Crystal Reports to name a few. The platform offers two authentication options such as using Windows Authentication credentials for easy one click connection; otherwise, the No Password option is available where you can gray out User Name field and remove password altogether while logging in once followed by storing URL after which subsequent connections are made with your stored user details like username being used\n"
          ]
        }
      ],
      "source": [
        "res = qa(f\"\"\"\n",
        "    What is defact planning?\n",
        "    Extract it from the text.\n",
        "\"\"\")\n",
        "print(res[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "457426ad",
      "metadata": {
        "id": "457426ad"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}